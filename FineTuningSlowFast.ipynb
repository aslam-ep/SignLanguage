{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningSlowFast.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSxBLvNUpmOf"
      },
      "source": [
        "**1. Installing the requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8kGrBOfpdIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48356a7c-417c-49a5-f9a6-0b891cbd4e7e"
      },
      "source": [
        "# for mxnet\n",
        "!pip install --upgrade mxnet\n",
        "# for pytorch\n",
        "!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install --upgrade gluoncv\n",
        "\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.6.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (154.6MB)\n",
            "\u001b[K     |████████████████████████████████| 154.6MB 80kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.7.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cpu) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0+cpu which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.6.0+cpu torchvision-0.7.0+cpu\n",
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/2b/f1cc4e7a0a654c00dae9d870d0d1f653e5760ad85297306b63e6be527dcf/gluoncv-0.10.1.post0-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.5MB/s \n",
            "\u001b[?25hCollecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Collecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 249kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Collecting autocfg\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f9/74e0a42cbc6d871c92288806e7812c7d2628c2a06557930dbab0a17438d2/autocfg-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Collecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting autogluon.core\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/15/1f0f86152ffb389214b848baf9c44ac02e266dbc218a4273de78dc09316f/autogluon.core-0.1.0-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 59.0MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx->gluoncv) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (1.3)\n",
            "Collecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b0/3454dc44239c526f9c9e4cf04f62823776b71f927db74302986d56e7a9a1/distributed-2021.4.0-py3-none-any.whl (684kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 55.9MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a5/892ed5d2959b1fdf4f8aaccf96b299e57dd7f06db7072592901fbaa36d79/boto3-1.17.54-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (2.12.0)\n",
            "Collecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 60.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.29.22)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn<0.25,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.3.3)\n",
            "Collecting ConfigSpace==0.4.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c3/3c21e8d82a639fd821f538e6d7f830b654a6ce1fe52644be1a67f323f707/ConfigSpace-0.4.18.tar.gz (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 55.6MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx->gluoncv) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx->gluoncv) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core->gluoncv) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (0.11.1)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.3.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.54\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/e1/59cc39d22d44e64e96186db87d6e670e2119822d16299e18d0500198abb4/botocore-1.20.54-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 49.2MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/50/ac379fa31377f5d316cad8967db9f73c50cd61b80153269bfd7d8b964fc8/s3transfer-0.4.0-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 56.8MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 59.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.22.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko>=2.4->autogluon.core->gluoncv) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.4->autogluon.core->gluoncv) (2.20)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2879796 sha256=9bfc5f2e62278a553f5f547d04f66f4107125d4fe6bbd5b0cbbb2db38e1751f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ea/40/d93931850f700427db0a84180829c709d30484c9475040c7bd\n",
            "Successfully built ConfigSpace\n",
            "\u001b[31mERROR: distributed 2021.4.0 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.54 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon-core 0.1.0 has requirement scipy==1.5.4, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardx, decord, autocfg, yacs, cloudpickle, distributed, jmespath, botocore, s3transfer, boto3, cryptography, bcrypt, pynacl, paramiko, ConfigSpace, autogluon.core, portalocker, gluoncv\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed ConfigSpace-0.4.18 autocfg-0.0.8 autogluon.core-0.1.0 bcrypt-3.2.0 boto3-1.17.54 botocore-1.20.54 cloudpickle-1.6.0 cryptography-3.4.7 decord-0.5.2 distributed-2021.4.0 gluoncv-0.10.1.post0 jmespath-0.10.0 paramiko-2.7.2 portalocker-2.3.0 pynacl-1.4.0 s3transfer-0.4.0 tensorboardx-2.2 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/4f/2e51ae21a0361db5363915f042f872a7d4ca456094a0b9e0f967bdcf7729/mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7MB)\n",
            "\u001b[K     |████████████████████████████████| 356.7MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Installing collected packages: mxnet-cu101\n",
            "Successfully installed mxnet-cu101-1.8.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8vzZ0gfp0qZ"
      },
      "source": [
        "**2. Changing the working directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewY4MbhoplUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08766e92-bd87-4012-e4c9-a76da508eff5"
      },
      "source": [
        "# Don't forget to mount the google drive\n",
        "%cd drive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhQT7e_Xp-pr"
      },
      "source": [
        "**3. Importing the requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIAGLmnplWZ"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluoncv as gcv\n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poJJSFLKqNH7"
      },
      "source": [
        "**4. Setting and loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3go3DMGkplao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5696c4ec-24ed-4fc1-8c7b-b4ff1fbef8c8"
      },
      "source": [
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "per_device_batch_size = 5\n",
        "num_workers = 0\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('DataSet/train/'),\n",
        "                               setting=os.path.expanduser('DataSet/train/train.txt'),\n",
        "                               slowfast=True,\n",
        "                               train=True,\n",
        "                               new_length=64,\n",
        "                               slow_temporal_stride=16,\n",
        "                               fast_temporal_stride=2,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               transform=transform_train)\n",
        "\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load 294 training samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jX6X0eHqbdA"
      },
      "source": [
        "**5. Loading the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KJALIpSplct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc289da-54cf-4c1c-8b63-995ca92a427a"
      },
      "source": [
        "net = get_model(name = 'slowfast_4x16_resnet50_custom', nclass = 6)\n",
        "net.collect_params().reset_ctx(ctx)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 134964/134964 [00:04<00:00, 30846.86KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SlowFast(\n",
            "  (fast_conv1): Conv3D(3 -> 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
            "  (fast_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "  (fast_relu): Activation(relu)\n",
            "  (fast_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (fast_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(8 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(32 -> 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(64 -> 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(128 -> 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (lateral_p1): HybridSequential(\n",
            "    (0): Conv3D(8 -> 16, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res2): HybridSequential(\n",
            "    (0): Conv3D(32 -> 64, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res3): HybridSequential(\n",
            "    (0): Conv3D(64 -> 128, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res4): HybridSequential(\n",
            "    (0): Conv3D(128 -> 256, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (slow_conv1): Conv3D(3 -> 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
            "  (slow_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "  (slow_relu): Activation(relu)\n",
            "  (slow_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (slow_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(80 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(80 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(320 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(320 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(640 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(640 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(1280 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(1280 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
            "  (dp): Dropout(p = 0.5, axes=())\n",
            "  (fc): Dense(2304 -> 6, linear)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEZ0sEVlqlmc"
      },
      "source": [
        "**6. Setting up the hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f1ZCUPFqkfs"
      },
      "source": [
        "# Learning rate decay factor\n",
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [40, 80, 100]\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'sgd'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AdXM00yple6"
      },
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiLYkgwRplg1"
      },
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wlE2vjq4xR"
      },
      "source": [
        "**7. Trainning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqeaf_SUpkfB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "cc4789cb-442e-4d56-fa40-ef55f1d35136"
      },
      "source": [
        "epochs = 12\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0] train=0.292517 loss=1.674142 time: 310.206685\n",
            "[Epoch 1] train=0.581633 loss=1.151713 time: 208.158032\n",
            "[Epoch 2] train=0.707483 loss=0.774064 time: 205.599636\n",
            "[Epoch 3] train=0.829932 loss=0.518897 time: 206.539372\n",
            "[Epoch 4] train=0.850340 loss=0.420811 time: 208.538515\n",
            "[Epoch 5] train=0.867347 loss=0.389243 time: 204.670315\n",
            "[Epoch 6] train=0.914966 loss=0.285852 time: 205.054644\n",
            "[Epoch 7] train=0.908163 loss=0.267842 time: 203.779069\n",
            "[Epoch 8] train=0.945578 loss=0.224573 time: 205.230999\n",
            "[Epoch 9] train=0.945578 loss=0.168930 time: 207.979764\n",
            "[Epoch 10] train=0.979592 loss=0.126800 time: 206.988502\n",
            "[Epoch 11] train=0.942177 loss=0.169094 time: 206.063117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudoD0AerBMk"
      },
      "source": [
        "**8. Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Rwi6Y8rEYf"
      },
      "source": [
        "net.save_parameters('Model/signof5_slowfast_4x16.params')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWf7zKbrH3V"
      },
      "source": [
        "**9. Running my infrence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64LiPPR9rM-U"
      },
      "source": [
        "# Map\n",
        "CLASS_MAP = {\n",
        "    0: \"Opaque\",\n",
        "    1: \"Red\",\n",
        "    2: \"Green\",\n",
        "    3: \"Yellow\",\n",
        "    4: \"Bright\",\n",
        "    5: \"Light-blue\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXzjOy_mrRQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400345c5-6dd3-4463-b5a8-13420cff815a"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = 'DataSet/test/001_001_001.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "fast_frame_id_list = range(0, 64, 2)\n",
        "slow_frame_id_list = range(0, 64, 16)\n",
        "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n",
        "\n",
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (36, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is readed and preprocessed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video data is readed and preprocessed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWYw2QSrWoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecf41e9-01ce-40af-93c7-57b4fd4cdd14"
      },
      "source": [
        "# Running the prediction\n",
        "pred = net(nd.array(clip_input,  ctx = mx.gpu(0)))\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (CLASS_MAP[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input video clip is classified to be\n",
            "\t[Green], with probability 0.224.\n",
            "\t[Bright], with probability 0.208.\n",
            "\t[Yellow], with probability 0.179.\n",
            "\t[Opaque], with probability 0.175.\n",
            "\t[Light-blue], with probability 0.112.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iOvnH5OozgW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}