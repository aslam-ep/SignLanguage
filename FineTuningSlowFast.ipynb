{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningSlowFast.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSxBLvNUpmOf"
      },
      "source": [
        "**1. Installing the requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8kGrBOfpdIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78db4c4c-2509-4892-a390-51f7b8b3f2f9"
      },
      "source": [
        "# for mxnet\n",
        "!pip install --upgrade mxnet\n",
        "# for pytorch\n",
        "!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install --upgrade gluoncv\n",
        "\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.6.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (154.6MB)\n",
            "\u001b[K     |████████████████████████████████| 154.6MB 54kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.7.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cpu) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0+cpu which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.6.0+cpu torchvision-0.7.0+cpu\n",
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/2b/f1cc4e7a0a654c00dae9d870d0d1f653e5760ad85297306b63e6be527dcf/gluoncv-0.10.1.post0-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Collecting autocfg\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f9/74e0a42cbc6d871c92288806e7812c7d2628c2a06557930dbab0a17438d2/autocfg-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.5MB/s \n",
            "\u001b[?25hCollecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 244kB/s \n",
            "\u001b[?25hCollecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.41.1)\n",
            "Collecting autogluon.core\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/15/1f0f86152ffb389214b848baf9c44ac02e266dbc218a4273de78dc09316f/autogluon.core-0.1.0-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx->gluoncv) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.29.22)\n",
            "Requirement already satisfied, skipping upgrade: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (2.12.0)\n",
            "Collecting ConfigSpace==0.4.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c3/3c21e8d82a639fd821f538e6d7f830b654a6ce1fe52644be1a67f323f707/ConfigSpace-0.4.18.tar.gz (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 32.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (5.1.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f2/52bf45246ad421cdd8c80a5c0f3e8f082e818d0467cde6aa8294258d1b4a/boto3-1.17.55-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 37.9MB/s \n",
            "\u001b[?25hCollecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b0/3454dc44239c526f9c9e4cf04f62823776b71f927db74302986d56e7a9a1/distributed-2021.4.0-py3-none-any.whl (684kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn<0.25,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.3.3)\n",
            "Collecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx->gluoncv) (54.2.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.55\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b0/d382d472989ce23bee0a36f8bd0c326d4694496611a7fe41fae51d71bf46/botocore-1.20.55-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 38.8MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/95/91a1b99e4ef46bb915167b04aa26aec74dad5356d13d487a90f7d22994ee/s3transfer-0.4.1-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.0.0)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.22.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core->gluoncv) (0.16.0)\n",
            "Collecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.4MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core->gluoncv) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core->gluoncv) (2.20)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2879764 sha256=aac0f7b27cad5e9168878842d7f2b4ffdc71ca66b33aee28247f44a2ba086d2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ea/40/d93931850f700427db0a84180829c709d30484c9475040c7bd\n",
            "Successfully built ConfigSpace\n",
            "\u001b[31mERROR: distributed 2021.4.0 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.55 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon-core 0.1.0 has requirement scipy==1.5.4, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: portalocker, autocfg, tensorboardx, decord, yacs, ConfigSpace, jmespath, botocore, s3transfer, boto3, cloudpickle, distributed, bcrypt, cryptography, pynacl, paramiko, autogluon.core, gluoncv\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed ConfigSpace-0.4.18 autocfg-0.0.8 autogluon.core-0.1.0 bcrypt-3.2.0 boto3-1.17.55 botocore-1.20.55 cloudpickle-1.6.0 cryptography-3.4.7 decord-0.5.2 distributed-2021.4.0 gluoncv-0.10.1.post0 jmespath-0.10.0 paramiko-2.7.2 portalocker-2.3.0 pynacl-1.4.0 s3transfer-0.4.1 tensorboardx-2.2 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/4f/2e51ae21a0361db5363915f042f872a7d4ca456094a0b9e0f967bdcf7729/mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7MB)\n",
            "\u001b[K     |████████████████████████████████| 356.7MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Installing collected packages: mxnet-cu101\n",
            "Successfully installed mxnet-cu101-1.8.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8vzZ0gfp0qZ"
      },
      "source": [
        "**2. Changing the working directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewY4MbhoplUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0422b0b6-4dab-4e1a-f392-505b84360781"
      },
      "source": [
        "# Don't forget to mount the google drive\n",
        "%cd drive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhQT7e_Xp-pr"
      },
      "source": [
        "**3. Importing the requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIAGLmnplWZ"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluoncv as gcv\n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poJJSFLKqNH7"
      },
      "source": [
        "**4. Setting and loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3go3DMGkplao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8356a1be-2168-48dc-ddd1-aac9c96e5a98"
      },
      "source": [
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "# transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66]),\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "per_device_batch_size = 5\n",
        "num_workers = 0\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('DataSet/train/'),\n",
        "                               setting=os.path.expanduser('DataSet/train/train.txt'),\n",
        "                               slowfast=True,\n",
        "                               train=True,\n",
        "                               new_length=64,\n",
        "                               slow_temporal_stride=16,\n",
        "                               fast_temporal_stride=2,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               transform=transform_train)\n",
        "\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load 294 training samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jX6X0eHqbdA"
      },
      "source": [
        "**5. Loading the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KJALIpSplct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc28df47-d308-4b73-eb53-a2c00bdaed8b"
      },
      "source": [
        "net = get_model(name = 'slowfast_4x16_resnet50_custom', nclass = 6)\n",
        "net.collect_params().reset_ctx(ctx)\n",
        "print(net)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 134964/134964 [00:04<00:00, 28839.49KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SlowFast(\n",
            "  (fast_conv1): Conv3D(3 -> 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
            "  (fast_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "  (fast_relu): Activation(relu)\n",
            "  (fast_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (fast_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(8 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(32 -> 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(64 -> 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(128 -> 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (lateral_p1): HybridSequential(\n",
            "    (0): Conv3D(8 -> 16, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res2): HybridSequential(\n",
            "    (0): Conv3D(32 -> 64, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res3): HybridSequential(\n",
            "    (0): Conv3D(64 -> 128, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res4): HybridSequential(\n",
            "    (0): Conv3D(128 -> 256, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (slow_conv1): Conv3D(3 -> 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
            "  (slow_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "  (slow_relu): Activation(relu)\n",
            "  (slow_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (slow_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(80 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(80 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(320 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(320 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(640 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(640 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(1280 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(1280 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
            "  (dp): Dropout(p = 0.5, axes=())\n",
            "  (fc): Dense(2304 -> 6, linear)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEZ0sEVlqlmc"
      },
      "source": [
        "**6. Setting up the hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f1ZCUPFqkfs"
      },
      "source": [
        "# Learning rate decay factor\n",
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [40, 80, 100]\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'sgd'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AdXM00yple6"
      },
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiLYkgwRplg1"
      },
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wlE2vjq4xR"
      },
      "source": [
        "**7. Trainning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqeaf_SUpkfB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "e253139c-4319-4b75-d0dc-1fc1f9032b45"
      },
      "source": [
        "epochs = 12\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0] train=0.265306 loss=1.710531 time: 524.743193\n",
            "[Epoch 1] train=0.646259 loss=1.171237 time: 297.808504\n",
            "[Epoch 2] train=0.693878 loss=0.746061 time: 301.305857\n",
            "[Epoch 3] train=0.744898 loss=0.592058 time: 300.259571\n",
            "[Epoch 4] train=0.819728 loss=0.429817 time: 300.074119\n",
            "[Epoch 5] train=0.826531 loss=0.428907 time: 307.001795\n",
            "[Epoch 6] train=0.908163 loss=0.316916 time: 306.871473\n",
            "[Epoch 7] train=0.918367 loss=0.265872 time: 301.985779\n",
            "[Epoch 8] train=0.972789 loss=0.166280 time: 300.221640\n",
            "[Epoch 9] train=0.948980 loss=0.189372 time: 297.485820\n",
            "[Epoch 10] train=0.962585 loss=0.152463 time: 301.439059\n",
            "[Epoch 11] train=0.962585 loss=0.139993 time: 298.652070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudoD0AerBMk"
      },
      "source": [
        "**8. Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Rwi6Y8rEYf"
      },
      "source": [
        "net.save_parameters('Model/signof5_slowfast_4x16.params')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWf7zKbrH3V"
      },
      "source": [
        "**9. Running my infrence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64LiPPR9rM-U"
      },
      "source": [
        "# Map\n",
        "CLASS_MAP = {\n",
        "    0: \"Opaque\",\n",
        "    1: \"Red\",\n",
        "    2: \"Green\",\n",
        "    3: \"Yellow\",\n",
        "    4: \"Bright\",\n",
        "    5: \"Light-blue\"\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXzjOy_mrRQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0580fb-8ffb-45af-e5bc-39e368fea202"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = 'DataSet/train/005_003_001.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "fast_frame_id_list = range(0, 64, 2)\n",
        "slow_frame_id_list = range(0, 64, 16)\n",
        "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n",
        "\n",
        "# transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform_fn = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66]),\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (36, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is readed and preprocessed.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video data is readed and preprocessed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWYw2QSrWoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bbd8d77-bb55-4ea2-9ad0-be554c98d71a"
      },
      "source": [
        "# Running the prediction\n",
        "pred = net(nd.array(clip_input,  ctx = mx.gpu(0)))\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (CLASS_MAP[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input video clip is classified to be\n",
            "\t[Bright], with probability 0.445.\n",
            "\t[Opaque], with probability 0.382.\n",
            "\t[Green], with probability 0.083.\n",
            "\t[Red], with probability 0.035.\n",
            "\t[Light-blue], with probability 0.030.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iOvnH5OozgW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}