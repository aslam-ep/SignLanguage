{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningI3D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBJpRS_WRQE"
      },
      "source": [
        "**1. Installing the requirements**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "laQS4fsmWEnH",
        "outputId": "d6b33827-668d-4ead-9061-93a6599958fd"
      },
      "source": [
        "# for mxnet\n",
        "!pip install --upgrade mxnet\n",
        "# for pytorch\n",
        "!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install --upgrade gluoncv\n",
        "\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.6.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (154.6MB)\n",
            "\u001b[K     |████████████████████████████████| 154.6MB 93kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cpu\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.7.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cpu) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0+cpu which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.6.0+cpu torchvision-0.7.0+cpu\n",
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/2b/f1cc4e7a0a654c00dae9d870d0d1f653e5760ad85297306b63e6be527dcf/gluoncv-0.10.1.post0-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 22.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Collecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 249kB/s \n",
            "\u001b[?25hCollecting autocfg\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f9/74e0a42cbc6d871c92288806e7812c7d2628c2a06557930dbab0a17438d2/autocfg-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 57.9MB/s \n",
            "\u001b[?25hCollecting autogluon.core\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/15/1f0f86152ffb389214b848baf9c44ac02e266dbc218a4273de78dc09316f/autogluon.core-0.1.0-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Collecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx->gluoncv) (3.12.4)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a5/892ed5d2959b1fdf4f8aaccf96b299e57dd7f06db7072592901fbaa36d79/boto3-1.17.54-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.4MB/s \n",
            "\u001b[?25hCollecting paramiko>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 61.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn<0.25,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.29.22)\n",
            "Requirement already satisfied, skipping upgrade: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.3.3)\n",
            "Collecting ConfigSpace==0.4.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c3/3c21e8d82a639fd821f538e6d7f830b654a6ce1fe52644be1a67f323f707/ConfigSpace-0.4.18.tar.gz (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 53.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (0.8.4)\n",
            "Collecting distributed>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b0/3454dc44239c526f9c9e4cf04f62823776b71f927db74302986d56e7a9a1/distributed-2021.4.0-py3-none-any.whl (684kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (2.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core->gluoncv) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx->gluoncv) (54.2.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.54\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/e1/59cc39d22d44e64e96186db87d6e670e2119822d16299e18d0500198abb4/botocore-1.20.54-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 47.5MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/50/ac379fa31377f5d316cad8967db9f73c50cd61b80153269bfd7d8b964fc8/s3transfer-0.4.0-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 45.0MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.22.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core->gluoncv) (0.16.0)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (0.11.1)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core->gluoncv) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pynacl>=1.0.1->paramiko>=2.4->autogluon.core->gluoncv) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core->gluoncv) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko>=2.4->autogluon.core->gluoncv) (2.20)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2879809 sha256=97c696871d13a3135c22e59746efce4434bdab9455ce894478011368c5255ecf\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ea/40/d93931850f700427db0a84180829c709d30484c9475040c7bd\n",
            "Successfully built ConfigSpace\n",
            "\u001b[31mERROR: distributed 2021.4.0 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.54 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autogluon-core 0.1.0 has requirement scipy==1.5.4, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: portalocker, decord, autocfg, tensorboardx, jmespath, botocore, s3transfer, boto3, pynacl, bcrypt, cryptography, paramiko, ConfigSpace, cloudpickle, distributed, autogluon.core, yacs, gluoncv\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed ConfigSpace-0.4.18 autocfg-0.0.8 autogluon.core-0.1.0 bcrypt-3.2.0 boto3-1.17.54 botocore-1.20.54 cloudpickle-1.6.0 cryptography-3.4.7 decord-0.5.2 distributed-2021.4.0 gluoncv-0.10.1.post0 jmespath-0.10.0 paramiko-2.7.2 portalocker-2.3.0 pynacl-1.4.0 s3transfer-0.4.0 tensorboardx-2.2 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/4f/2e51ae21a0361db5363915f042f872a7d4ca456094a0b9e0f967bdcf7729/mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7MB)\n",
            "\u001b[K     |████████████████████████████████| 356.7MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Installing collected packages: mxnet-cu101\n",
            "Successfully installed mxnet-cu101-1.8.0.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8vzZ0gfp0qZ"
      },
      "source": [
        "**2. Changing the working directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kFvgyGvgDmY",
        "outputId": "bd13d15b-632c-403d-98bb-f4426e4f6140"
      },
      "source": [
        "# Don't forget to mount the google drive\n",
        "%cd drive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlk4oSsdhGaH"
      },
      "source": [
        "**3. Importing the requirments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gEmw5sMg3LB"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluoncv as gcv\n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Os4bD85xROi"
      },
      "source": [
        "**4. Setting and loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDwVWE54gkPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85985fc4-48a3-4d00-bbd2-89274f3970e9"
      },
      "source": [
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "per_device_batch_size = 5\n",
        "num_workers = 0\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('DataSet/train/'),\n",
        "                               setting=os.path.expanduser('DataSet/train/train.txt'),\n",
        "                               train=True,\n",
        "                               new_length=64,\n",
        "                               new_step=2,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               transform=transform_train)\n",
        "\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load 294 training samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVPlnv3_yFyV"
      },
      "source": [
        "**5. Loading the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ggba8O6k-wA",
        "outputId": "5d19f98d-3ab7-4b41-a294-7017a291504f"
      },
      "source": [
        "net = get_model(name='i3d_resnet50_v1_custom', nclass=6)\n",
        "net.collect_params().reset_ctx(ctx)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55344/55344 [00:01<00:00, 43504.46KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "conv0_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm0_gamma is done with shape:  (64,)\n",
            "batchnorm0_beta is done with shape:  (64,)\n",
            "batchnorm0_running_mean is done with shape:  (64,)\n",
            "batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense0_weight is skipped with shape:  (6, 2048)\n",
            "dense0_bias is skipped with shape:  (6,)\n",
            "Downloading /root/.mxnet/models/i3d_resnet50_v1_kinetics400-568a722e.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 208483/208483 [00:03<00:00, 54393.91KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I3D_ResNetV1(\n",
            "  (first_stage): HybridSequential(\n",
            "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "    (2): Activation(relu)\n",
            "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  )\n",
            "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (res_layers): HybridSequential(\n",
            "    (0): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=256)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (1): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=512)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (2): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=1024)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (3): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=2048)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
            "  (head): HybridSequential(\n",
            "    (0): Dropout(p = 0.8, axes=())\n",
            "    (1): Dense(2048 -> 6, linear)\n",
            "  )\n",
            "  (fc): Dense(2048 -> 6, linear)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEZ0sEVlqlmc"
      },
      "source": [
        "**6. Setting up the hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8R9iZsPlDm1"
      },
      "source": [
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [40, 80, 100]\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'sgd'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxK6g2cklGTw"
      },
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnitvEFlISM"
      },
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2wlE2vjq4xR"
      },
      "source": [
        "**7. Trainning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR9dN5dlJwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "39b59b64-28d6-41ba-f798-ff8ffb3390dd"
      },
      "source": [
        "epochs = 10\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] accuracy= %f loss= %f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0] accuracy= 0.282313 loss= 1.682717 time: 452.010983\n",
            "[Epoch 1] accuracy= 0.717687 loss= 1.015411 time: 279.712129\n",
            "[Epoch 2] accuracy= 0.877551 loss= 0.500941 time: 280.045598\n",
            "[Epoch 3] accuracy= 0.935374 loss= 0.289778 time: 278.159643\n",
            "[Epoch 4] accuracy= 0.976190 loss= 0.148122 time: 277.360273\n",
            "[Epoch 5] accuracy= 0.969388 loss= 0.128445 time: 277.629652\n",
            "[Epoch 6] accuracy= 0.982993 loss= 0.094803 time: 278.458973\n",
            "[Epoch 7] accuracy= 0.972789 loss= 0.116997 time: 280.184779\n",
            "[Epoch 8] accuracy= 0.993197 loss= 0.098100 time: 283.152520\n",
            "[Epoch 9] accuracy= 0.989796 loss= 0.068066 time: 280.974854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudoD0AerBMk"
      },
      "source": [
        "**8. Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooqs46lM9GTi"
      },
      "source": [
        "net.save_parameters('Model/i3d_resnet50_v1.params')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWf7zKbrH3V"
      },
      "source": [
        "**9. Running my infrence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPvUn4P_SUhn"
      },
      "source": [
        "# Map\n",
        "CLASS_MAP = {\n",
        "    0: \"Opaque\",\n",
        "    1: \"Red\",\n",
        "    2: \"Green\",\n",
        "    3: \"Yellow\",\n",
        "    4: \"Bright\",\n",
        "    5: \"Light-blue\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24lM2Xf3td-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febc2b7f-4fb3-4ef1-fb84-644c017c531c"
      },
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = 'DataSet/train/006_002_001.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list = range(0, 64, 2)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n",
        "\n",
        "transform_fn = video.VideoGroupValTransform(size=(224, 224), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is readed and preprocessed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video data is readed and preprocessed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73JMNAs-4z8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159f1fd8-4b0b-44b1-92ec-f0a80893ffe9"
      },
      "source": [
        "# Running the prediction\n",
        "pred = net(nd.array(clip_input,  ctx = mx.gpu(0)))\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (CLASS_MAP[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input video clip is classified to be\n",
            "\t[Yellow], with probability 0.554.\n",
            "\t[Red], with probability 0.124.\n",
            "\t[Bright], with probability 0.118.\n",
            "\t[Light-blue], with probability 0.098.\n",
            "\t[Green], with probability 0.059.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFEaylkxN4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}